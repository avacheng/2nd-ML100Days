# 2nd-ML100* Days
##### 第 2 屆 機器學習 百日馬拉松 業界專家陪你升級打怪

#### 資料清理數據前處理
* Day001-資料介紹與評估指標
* Day002-EDA1讀取資料
* Day003-如何新建一個dataframe
* Day004-EDA資料類型介紹
* Day005-EDA資料分布
* Day006-EDA與outlier檢查
* Day007-常用的數值取代_中位數與分位數連續數值標準化
* Day008-常用的 DataFrame 操作

#### 探索式數據分析
* Day009-EDA correlation相關係數簡介
* Day010-EDA from Correlation
* Day011-EDA不同數值範圍間的特徵如何檢視 繪圖與樣式Kernel Density Estimation (KDE)
* Day012-EDA把連續型變數離散化
* Day013-程式實作 把連續型變數離散化
* Day014-Subplots
* Day015-Heatmap Grid-plot
* Day016-模型初體驗Logistic Regression

#### 資料科學特徵工程技術
* Day017-特徵工程簡介
* Day018-特徵類型
* Day019-數值型特徵補缺失值與標準化
* Day020-數值型特徵-去除離群值
* Day021-數值型特徵-去除偏態
* Day022-類別型特徵-基礎處理理
* Day023-類別型特徵-均值編碼
* Day024-類別型特徵-其他進階處理
* Day025-時間型特徵
* Day026-特徵組合-數值與數值組合
* Day027-特徵組合-類別與數值組合
* Day028-特徵選擇
* Day029-特徵評估
* Day030-分類型特徵優化 - 葉編碼

#### 機器學習基礎模型建立
* Day031-機器學習概論
* Day032-流程與步驟
* Day033-機器如何學習
* Day034-訓練測試集切分的概念
* Day035-regression vs classification
* Day036-評估指標選定 valuation metrics
* Day037-regression model 介紹 - 線性迴歸 羅吉斯回歸
* Day038-Regression 模型-程式碼
* Day039-regression model 介紹 LASSO 回歸 Ridge 回歸
* Day040-regression model 程式碼撰寫
* Day041-tree based model-決策樹Decision Tree模型介紹
* Day042-tree based model決策樹程式碼撰寫
* Day043-tree based model隨機森林Random Forest介紹
* Day044-tree based model隨機森林程式碼撰寫
* Day045-tree based model梯度提升機
* Day046-tree based梯度提升機-程式碼撰寫

#### 機器學習調整參數
* Day047-參數調整-超參數調整與優化
* Day048-參數調整-Kaggle-Home of Data Science
* Day049-集成-混合泛化(Blending)
* Day050-集成-堆疊泛化(Stacking)

#### 非監督式機器學習
* Day054-簡介
* Day055-Kmeans聚類算法
* Day056-Kmeans觀察-使用輪廓分析
* Day057-階層分群算法
* Day058-階層分群法使用2D樣板資料集
* Day059-主成分分析
* Day060-PCA觀察使用手寫辨識資料集
* Day061-降維方法t-SNE
* Day062-t-SNE觀察分群與流形還原

#### 深度學習理論與實作
* Day063-深度學習簡介
* Day064-體驗模型調整與學習曲線
* Day065-啟動函數與正規化

#### 初探深度學習使用Keras
* Day066-Keras的介紹與應用
* Day066-Keras的介紹與應用-2
* Day067-eras embedded dataset介紹與應用
* Day068-SequentialAPI-序列模型搭建網路
* Day069-KerasModuleAPI-介紹與應用
* Day070-Multi-layerPerceptron-多層感知器簡介
* Day071-損失函數-介紹
* Day072-啟動函數-介紹與應⽤
* Day073-GradientDescent-梯度下降簡介
* Day074-GradientDescent-梯度下降數學原理
* Day075-BackPropagation-反向式傳播簡介
* Day076-Optimizers-優化器簡介
* Day077-訓練的細節與技巧ValidationOverfitting
* Day078-訓練前的注意事項
* Day079-Learning rate effect
* Day080-優化器與學習綠的組合與比較
* Day081-Regularization正規化
* Day082-Dropout隨機丟失
* Day083-Batch normalization
* Day084-正規化隨+機移除+批次標準化的組合與比較
* Day085-使用callbacks函數做earlystop
* Day086-使用callbacks函數儲存model
* Day087-使用callbacks函數做reduce learning rate
* Day088-撰寫自己的callbacks函數
* Day089-撰寫自己的Loss function
* Day090-傳統電腦視覺與影像辨識
* Day091-傳統電腦視覺與影像辨識Coding

#### 深度學習應用卷積神經網路
* Day092-卷積神經網路簡介
* Day093-卷積神經網路架構細節
* Day094-卷積層與參數調整
* Day095-卷積層與參數調整2
* Day096-Keras 中的 CNN layers
* Day097-使用CNN完成Cifar-10資料集
* Day098-處理大量數據
* Day099-處理小量數據
* Day100-遷移學習
